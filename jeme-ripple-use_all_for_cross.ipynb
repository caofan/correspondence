{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "os.chdir(\"jeme/JEME vs Ripple/\")\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.externals.joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve, f1_score, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['K562_Ctcf_E', 'K562_Dnase1_E', 'K562_H3k27ac_E', 'K562_H3k27me3_E',\n",
       "       'K562_H3k36me3_E', 'K562_H3k4me2_E', 'K562_H3k9ac_E', 'K562_H4k20me1_E',\n",
       "       'K562_Rad21_E', 'K562_Tbp_E', 'K562_Ctcf_P', 'K562_Dnase1_P',\n",
       "       'K562_H3k27ac_P', 'K562_H3k27me3_P', 'K562_H3k36me3_P',\n",
       "       'K562_H3k4me2_P', 'K562_H3k9ac_P', 'K562_H4k20me1_P', 'K562_Rad21_P',\n",
       "       'K562_Tbp_P', 'K562_Correlation', 'K562_Exp', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('Ripple/K562_enhanceronly_features.txt', delimiter='\\t').set_index('Pair').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, f1_score\n",
    "\n",
    "def aupr_auroc_f1(estimator, X, y):\n",
    "    probs = estimator.predict_proba(X)\n",
    "    preds = estimator.predict(X)\n",
    "    aupr = average_precision_score(y, probs[:,1])\n",
    "    auroc = roc_auc_score(y, probs[:,1])\n",
    "    f1 = f1_score(y, preds)\n",
    "    return aupr, auroc, f1\n",
    "\n",
    "def train_a_ripple(train_data, train_label, test_data, test_label):\n",
    "    rfc = RandomForestClassifier(**params)\n",
    "    rfc.fit(train_data, train_label)\n",
    "    return aupr_auroc_f1(rfc, test_data, test_label)\n",
    "\n",
    "def train_an_ripple_intra(train_data, train_label, groups, seed):\n",
    "    rfc = RandomForestClassifier(**params)\n",
    "    train_data, train_label, groups = shuffle(train_data, train_label, groups, random_state=seed)\n",
    "    cv = GroupKFold(5)\n",
    "    cv = cv.split(train_data, train_label, groups)\n",
    "    probs = cross_val_predict(rfc, train_data, train_label, cv=cv, n_jobs=1, method='predict_proba')\n",
    "    preds = probs[:,1]>=0.5\n",
    "    return (average_precision_score(train_label, probs[:,1]),\n",
    "            roc_auc_score(train_label, probs[:,1]),\n",
    "            f1_score(train_label, preds))\n",
    "\n",
    "def train_ripple_cv(to_shuffle):\n",
    "    train = pd.read_csv('Ripple/K562_enhanceronly_features.txt', delimiter='\\t').set_index('Pair')\n",
    "    \n",
    "    chrom_info = {}\n",
    "    keys = ['chrom1', 'start1', 'end1', 'chrom2', 'start2', 'end2']\n",
    "    for k in keys:\n",
    "        chrom_info[k] = []\n",
    "\n",
    "    for i in train.index:\n",
    "        chrom1, start1, end1 = i.split('-')[0].split('_')\n",
    "        chrom2, start2, end2 = i.split('-')[1].split('_')\n",
    "        \n",
    "        for k,d in zip(keys, [chrom1, start1, end1, chrom2, start2, end2]):\n",
    "            if d.isdigit():\n",
    "                d = int(d)\n",
    "            chrom_info[k].append(d)\n",
    "        \n",
    "    for k in keys:\n",
    "        train[k] = chrom_info[k]\n",
    "    train = train.sort_values(by=keys)\n",
    "    train = train.drop(keys, axis=1)\n",
    "    \n",
    "    \n",
    "    cv = StratifiedKFold(n_splits = 5, shuffle = to_shuffle, random_state=0)\n",
    "    cv = cv.split(train.iloc[:, :-1], train['Class'])\n",
    "    \n",
    "    tasks = []\n",
    "    for train_idx, test_idx in cv:\n",
    "        tasks.append(delayed(train_a_ripple)(train.ix[train_idx, :-1], train.ix[train_idx, 'Class'],\n",
    "                                        train.ix[test_idx, :-1], train.ix[test_idx, 'Class']))\n",
    "\n",
    "    \n",
    "    with Parallel(n_jobs=20) as parallel:\n",
    "        scores = parallel(tasks)\n",
    "    auprcs = [x[0] for x in scores]\n",
    "    aurocs = [x[1] for x in scores]\n",
    "    f1s = [x[2] for x in scores]\n",
    "\n",
    "    print(\"\\nCV\")\n",
    "    print(np.mean(auprcs), np.mean(aurocs), np.mean(f1s))\n",
    "    print(np.std(auprcs), np.std(aurocs), np.std(f1s))\n",
    "    print('dummy:', np.sum(train['Class'])/train.shape[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_ripple_intra():\n",
    "    train = pd.read_csv('Ripple/K562_enhanceronly_features.txt', delimiter='\\t').set_index('Pair')       \n",
    "    train = train.sort_index()\n",
    "    \n",
    "    \n",
    "    total_pos = np.sum(train['Class'])\n",
    "    total_neg = np.sum(train['Class']==0)\n",
    "    all_chrom_counts = {}\n",
    "    print('counting')\n",
    "    \n",
    "    \n",
    "    for i in train.index:\n",
    "        curr_chrom = i.split('_')[0]+'_'\n",
    "    \n",
    "        if curr_chrom not in all_chrom_counts:\n",
    "            all_chrom_counts[curr_chrom] = [0,0]\n",
    "        if train.loc[i, 'Class'] == 0:\n",
    "            all_chrom_counts[curr_chrom][1] += 1\n",
    "        else:\n",
    "            all_chrom_counts[curr_chrom][0] += 1\n",
    "    all_chroms = sorted(list(all_chrom_counts.keys()))\n",
    "    chrom_to_group_map = dict([(all_chroms[i], i) for i in range(len(all_chroms))])\n",
    "    groups = []\n",
    "    for i in train.index:\n",
    "        curr_chrom = i.split('_')[0]+'_'\n",
    "        groups.append(chrom_to_group_map[curr_chrom])\n",
    "    tasks = []\n",
    "    dummy_avg = []\n",
    "    for seed in [0,29,192,92,123,2212]:\n",
    "\n",
    "        tasks.append(delayed(train_an_jeme_intra)(train.ix[:,:-1], train['Class'], groups, seed))\n",
    "        dummy_avg.append(np.sum(train['Class']) / len(train['Class']))\n",
    "        \n",
    "    \n",
    "    scores = []\n",
    "    with Parallel(n_jobs=20) as parallel:\n",
    "        scores = parallel(tasks)\n",
    "    auprcs = [x[0] for x in scores]\n",
    "    aurocs = [x[1] for x in scores]\n",
    "    f1s = [x[2] for x in scores]\n",
    "\n",
    "    print(\"\\nIntra\")\n",
    "    print(np.mean(auprcs), np.mean(aurocs), np.mean(f1s))\n",
    "    print(np.std(auprcs), np.std(aurocs), np.std(f1s))\n",
    "    print(\"dummpy\", dummy_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_ripple():\n",
    "    train = pd.read_csv('Ripple/K562_enhanceronly_features.txt', delimiter='\\t').set_index('Pair')  \n",
    "    test = pd.read_csv('Ripple/Gm12878_enhanceronly_features.txt', delimiter='\\t').set_index('Pair')  \n",
    "\n",
    "    train = train.sort_index()\n",
    "    test = test.sort_index()\n",
    "    train_data = train.iloc[:, :-1]\n",
    "    train_labels = train['Class']\n",
    "\n",
    "    test_data = test.iloc[:, :-1]\n",
    "    test_labels = test['Class']\n",
    "    train_data.fillna(0)\n",
    "    test_data.fillna(0)\n",
    "\n",
    "    estimator = RandomForestClassifier(**params)\n",
    "\n",
    "    estimator.fit(train_data, train_labels)\n",
    "    probs = estimator.predict_proba(test_data)\n",
    "    preds = estimator.predict(test_data)\n",
    "    print(\"\\nAcross sample\")\n",
    "    print(average_precision_score(test_labels, probs[:,1]), \n",
    "          roc_auc_score(test_labels, probs[:,1]),\n",
    "          f1_score(test_labels, preds))\n",
    "    print(\"dummpy\", np.sum(test_labels) / len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting\n",
      "\n",
      "Intra\n",
      "0.643721751398 0.658038291799 0.565338953232\n",
      "0.0018264136015 0.00132044377955 0.00457227088557\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.625063511801 0.648328173817 0.555084430666\n",
      "0.00497496007052 0.00391229775708 0.00942232703241\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.591096661447 0.625029308044 0.557593031386\n",
      "0.00410794892139 0.00428825948954 0.00531868479096\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "for i in [5,10,None]:\n",
    "    params = {'n_estimators': 100, 'max_depth':i,\n",
    "              'random_state': 0, 'n_jobs': 10}\n",
    "    #train_ripple_cv(True)\n",
    "    #train_ripple_cv(False)\n",
    "    train_ripple_intra()\n",
    "    #train_ripple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_an_jeme(train_data, train_label, test_data, test_label):\n",
    "    rfc = RandomForestClassifier(**params)\n",
    "    rfc.fit(train_data, train_label)\n",
    "    return aupr_auroc_f1(rfc, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_an_jeme_intra(train_data, train_label, groups, seed):\n",
    "    rfc = RandomForestClassifier(**params)\n",
    "    train_data, train_label, groups = shuffle(train_data, train_label, groups, random_state=seed)\n",
    "    cv = GroupKFold(5)\n",
    "    cv = cv.split(train_data, train_label, groups)\n",
    "    probs = cross_val_predict(rfc, train_data, train_label, cv=cv, n_jobs=1, method='predict_proba')\n",
    "    preds = probs[:,1]>=0.5\n",
    "    return (average_precision_score(train_label, probs[:,1]),\n",
    "            roc_auc_score(train_label, probs[:,1]),\n",
    "            f1_score(train_label, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_jeme_cv(columns, to_shuffle):\n",
    "    train = pd.read_csv('./JEME/K562/all.sw.se.sp.csv').set_index('id3')\n",
    "    train = train.drop(['id1', 'id2'], axis=1)\n",
    "    \n",
    "    #train['id4'] = np.log10(train['id4'])\n",
    "    chrom_info = {}\n",
    "    keys = ['chrom1', 'start1', 'end1', 'chrom2', 'start2', 'end2']\n",
    "    for k in keys:\n",
    "        chrom_info[k] = []\n",
    "    for idx in train.index:\n",
    "        idx = idx.replace(':', ' ').replace('-', ' ').replace('_', ' ').replace('$', ' ').strip()\n",
    "        tokens = idx.split()\n",
    "        for k, d in zip(keys, tokens):\n",
    "            if d.isdigit():\n",
    "                d = int(d)\n",
    "            chrom_info[k].append(d)\n",
    "\n",
    "    for k in keys:\n",
    "        train[k] = chrom_info[k]\n",
    "    train = train.sort_values(by=keys)\n",
    "    train = train.drop(keys, axis=1)\n",
    "    cv = StratifiedKFold(n_splits = 5, shuffle=to_shuffle, random_state = 0)\n",
    "    cv = cv.split(train.loc[:, columns], train['id21'])\n",
    "\n",
    "    \n",
    "    tasks = []\n",
    "    for train_idx, test_idx in cv:\n",
    "        tasks.append(delayed(train_an_jeme)(train.ix[train_idx, columns], train.ix[train_idx, 'id21'],\n",
    "                                        train.ix[test_idx, columns], train.ix[test_idx, 'id21']))\n",
    "    \n",
    "    with Parallel(n_jobs=20) as parallel:\n",
    "        scores = parallel(tasks)\n",
    "    auprcs = [x[0] for x in scores]\n",
    "    aurocs = [x[1] for x in scores]\n",
    "    f1s = [x[2] for x in scores]\n",
    "\n",
    "    print(\"\\nCV\")\n",
    "    print(np.mean(auprcs), np.mean(aurocs), np.mean(f1s))\n",
    "    print(np.std(auprcs), np.std(aurocs), np.std(f1s))\n",
    "    print('dummy:', np.sum(train['id21'])/train.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_jeme_intra(columns):\n",
    "    train = pd.read_csv('./JEME/K562/all.sw.se.sp.csv').set_index('id3')\n",
    "    train = train.drop(['id1', 'id2'], axis=1)\n",
    "    #train['id4'] = np.log10(train['id4'])\n",
    "    \n",
    "    total_pos = np.sum(train['id21'])\n",
    "    total_neg = np.sum(train['id21']==0)\n",
    "    all_chrom_counts = {}\n",
    "    print('counting')\n",
    "    for i in train.index:\n",
    "        curr_chrom = i.split(':')[0]+':'\n",
    "    \n",
    "        if curr_chrom not in all_chrom_counts:\n",
    "            all_chrom_counts[curr_chrom] = [0,0]\n",
    "        if train.loc[i, 'id21'] == 0:\n",
    "            all_chrom_counts[curr_chrom][1] += 1\n",
    "        else:\n",
    "            all_chrom_counts[curr_chrom][0] += 1\n",
    "    all_chroms = sorted(list(all_chrom_counts.keys()))\n",
    "    chrom_to_group_map = dict([(all_chroms[i], i) for i in range(len(all_chroms))])\n",
    "    groups = []\n",
    "    for i in train.index:\n",
    "        curr_chrom = i.split(':')[0]+':'\n",
    "        groups.append(chrom_to_group_map[curr_chrom])\n",
    "    tasks = []\n",
    "    dummy_avg = []\n",
    "    for seed in range(0,200,10):\n",
    "\n",
    "        tasks.append(delayed(train_an_jeme_intra)(train.ix[:,columns], train['id21'], groups, seed))\n",
    "        dummy_avg.append(np.sum(train['id21']) / len(train['id21']))\n",
    "        \n",
    "    scores = []\n",
    "    with Parallel(n_jobs=20) as parallel:\n",
    "        scores = parallel(tasks)\n",
    "    auprcs = [x[0] for x in scores]\n",
    "    aurocs = [x[1] for x in scores]\n",
    "    f1s = [x[2] for x in scores]\n",
    "    print(\"\\nIntra\")\n",
    "    print(np.mean(auprcs), np.mean(aurocs), np.mean(f1s))\n",
    "    print(np.std(auprcs), np.std(aurocs), np.std(f1s))\n",
    "    print(\"dummpy\", dummy_avg)\n",
    "    \n",
    "    \n",
    "    \n",
    "def train_jeme_intra_cv(columns):\n",
    "    train = pd.read_csv('./JEME/K562/all.sw.se.sp.csv').set_index('id3')\n",
    "    train = train.drop(['id1', 'id2'], axis=1)\n",
    "    #train['id4'] = np.log10(train['id4'])\n",
    "    \n",
    "    total_pos = np.sum(train['id21'])\n",
    "    total_neg = np.sum(train['id21']==0)\n",
    "    all_chrom_counts = {}\n",
    "    print('counting')\n",
    "    for i in train.index:\n",
    "        curr_chrom = i.split(':')[0]+':'\n",
    "    \n",
    "        if curr_chrom not in all_chrom_counts:\n",
    "            all_chrom_counts[curr_chrom] = [0,0]\n",
    "        if train.loc[i, 'id21'] == 0:\n",
    "            all_chrom_counts[curr_chrom][1] += 1\n",
    "        else:\n",
    "            all_chrom_counts[curr_chrom][0] += 1\n",
    "    all_chroms = sorted(list(all_chrom_counts.keys()))\n",
    "    chrom_to_group_map = dict([(all_chroms[i], i) for i in range(len(all_chroms))])\n",
    "    groups = []\n",
    "    for i in train.index:\n",
    "        curr_chrom = i.split(':')[0]+':'\n",
    "        groups.append(chrom_to_group_map[curr_chrom])\n",
    "    tasks = []\n",
    "    dummy_avg = []\n",
    "    cv = GroupKFold(n_splits = 5)\n",
    "    cv = cv.split(train.loc[:, columns], train['id21'], groups)\n",
    "\n",
    "    \n",
    "    tasks = []\n",
    "    for train_idx, test_idx in cv:\n",
    "        tasks.append(delayed(train_an_jeme)(train.ix[train_idx, columns], train.ix[train_idx, 'id21'],\n",
    "                                        train.ix[test_idx, columns], train.ix[test_idx, 'id21']))\n",
    "        \n",
    "    scores = []\n",
    "    with Parallel(n_jobs=20) as parallel:\n",
    "        scores = parallel(tasks)\n",
    "    auprcs = [x[0] for x in scores]\n",
    "    aurocs = [x[1] for x in scores]\n",
    "    f1s = [x[2] for x in scores]\n",
    "    print(\"\\nIntra\")\n",
    "    print(np.mean(auprcs), np.mean(aurocs), np.mean(f1s))\n",
    "    print(np.std(auprcs), np.std(aurocs), np.std(f1s))\n",
    "    print(\"dummpy\", dummy_avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_jeme(columns):\n",
    "    train = pd.read_csv('./JEME/K562/all.sw.se.sp.csv').set_index('id3')\n",
    "    train = train.drop(['id1', 'id2'], axis=1)\n",
    "\n",
    "    #train['id4'] = np.log10(train['id4'])\n",
    "    test = pd.read_csv('./JEME/GM12878/all.sw.se.sp.csv').set_index('id3')\n",
    "    test = test.drop(['id1', 'id2'], axis=1)\n",
    "\n",
    "    \n",
    "    train_data = train.loc[:, columns]\n",
    "\n",
    "    test_data = test.loc[:, columns]\n",
    "    \n",
    "    train_labels = train['id21']\n",
    "\n",
    "    test_labels = test['id21']\n",
    "    \n",
    "    rfc = RandomForestClassifier(**params)\n",
    "    rfc.fit(train_data, train_labels)\n",
    "    probs = rfc.predict_proba(test_data)\n",
    "    preds = rfc.predict(test_data)\n",
    "    print(\"\\n\\nAcross sample\")\n",
    "    print(average_precision_score(test_labels, probs[:,1]), \n",
    "          roc_auc_score(test_labels, probs[:,1]),\n",
    "          f1_score(test_labels, preds))\n",
    "    print(\"dummpy\", np.sum(test_labels) / len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting\n",
      "\n",
      "Intra\n",
      "0.548928446424 0.559509783144 0.494832395946\n",
      "0.00412793790944 0.00445781997055 0.00931789301525\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.550598853542 0.556610627086 0.459737685022\n",
      "0.00478817411924 0.00523194890354 0.0101790753056\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.553426045043 0.55804617951 0.446072084234\n",
      "0.00478764981287 0.00477943051507 0.00833452237395\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "for i in [5,10,None]:\n",
    "    columns = ['id%d' % i for i in range(4,21)]\n",
    "    params = {'n_estimators': 100, 'max_depth': i,\n",
    "              'random_state': 0, 'n_jobs': 10}\n",
    "    #train_jeme_cv(columns, to_shuffle=True)\n",
    "    #train_jeme_cv(columns, to_shuffle=False)\n",
    "    train_jeme_intra(columns)\n",
    "    #train_jeme_intra_cv(columns)\n",
    "    #train_jeme(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting\n",
      "\n",
      "Intra\n",
      "0.404937078308 0.342110686244 0.355817061383\n",
      "0.00215615528353 0.00261283193717 0.00693806016824\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.442220618997 0.404611417591 0.431517381963\n",
      "0.00168411012339 0.00236190096386 0.00673259741878\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.494017020984 0.490500878266 0.503843786089\n",
      "0.00283754620843 0.0022114755283 0.000358154332886\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "for i in [5,10,None]:\n",
    "    columns = ['id4']\n",
    "    params = {'n_estimators': 100, 'max_depth': i,\n",
    "              'random_state': 0, 'n_jobs': 10}\n",
    "    #train_jeme_cv(columns, to_shuffle=True)\n",
    "    #train_jeme_cv(columns, to_shuffle=False)\n",
    "    train_jeme_intra(columns)\n",
    "    #train_jeme(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting\n",
      "\n",
      "Intra\n",
      "0.549380467654 0.560359380546 0.499226638026\n",
      "0.00441518253233 0.00378483182137 0.00984107857963\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.554124528342 0.561291896418 0.472930501216\n",
      "0.00724440785302 0.00681383846039 0.0104196220015\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.552105678785 0.560672949531 0.449255842202\n",
      "0.00565355224459 0.00689092930662 0.00869430860741\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "for i in [5,10,None]:\n",
    "    columns = ['id%d' % i for i in range(5,21)]\n",
    "    params = {'n_estimators': 100, 'max_depth':i,\n",
    "              'random_state': 0, 'n_jobs': 10}\n",
    "    #train_jeme_cv(columns, to_shuffle=True)\n",
    "    #train_jeme_cv(columns, to_shuffle=False)\n",
    "    train_jeme_intra(columns)\n",
    "    #train_jeme(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.548622864868 0.55710937307 0.50315297499\n",
      "0.00480894594456 0.00467342765902 0.00787009937873\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n",
      "\n",
      "10\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.547791507673 0.548393182418 0.46409804488\n",
      "0.00468091972693 0.00430869287688 0.00854695431817\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n",
      "\n",
      "None\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.541394467523 0.544461364739 0.441148298451\n",
      "0.00436242492478 0.00609369636208 0.010607436905\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['id%d' % i for i in range(9,21)]\n",
    "for i in [5,10,None]:\n",
    "    print(i)\n",
    "    params = {'n_estimators': 100, 'max_depth': i,\n",
    "              'random_state': 0, 'n_jobs': 10}\n",
    "    #train_jeme_cv(columns, to_shuffle=True)\n",
    "    #train_jeme_cv(columns, to_shuffle=False)\n",
    "    train_jeme_intra(columns)\n",
    "    #train_jeme(columns)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.548897288635 0.558298282863 0.503351943028\n",
      "0.00500178569337 0.00469266062055 0.00815400051882\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n",
      "\n",
      "10\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.547798269426 0.547703311148 0.460300182332\n",
      "0.00440201160898 0.00606121618874 0.00847391144899\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n",
      "\n",
      "None\n",
      "counting\n",
      "\n",
      "Intra\n",
      "0.543362046592 0.543578027873 0.440051218437\n",
      "0.00697200633646 0.00726172594965 0.0093805819978\n",
      "dummpy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['id%d' % i for i in range(9,21)] + ['id4']\n",
    "for i in [5,10,None]:\n",
    "    print(i)\n",
    "    params = {'n_estimators': 100, 'max_depth': i,\n",
    "              'random_state': 0, 'n_jobs': 10}\n",
    "    #train_jeme_cv(columns, to_shuffle=True)\n",
    "    #train_jeme_cv(columns, to_shuffle=False)\n",
    "    train_jeme_intra(columns)\n",
    "    #train_jeme(columns)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
